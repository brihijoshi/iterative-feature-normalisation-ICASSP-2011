{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import os\n",
    "from feature_extraction import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"../data/processed/train2/\"\n",
    "# TEST_PATH = \"../data/processed/test/\"\n",
    "REF_PATH = \"../data/processed/reference/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_df(PATH):\n",
    "    all_files = os.listdir(PATH)\n",
    "    df = pd.DataFrame(all_files, columns=['file'])\n",
    "    df['speaker'] = df['file'].apply(lambda x: int(x.split('.')[0].split('-')[-1]))\n",
    "    # 0 for neutral, 1 for emotional\n",
    "    df['speech_type'] = df['file'].apply(lambda x: 0 if int(x.split('.')[0].split('-')[2])==1 else 1)\n",
    "    df['F0_contour'] = df['file'].apply(lambda x: get_F0_contour(PATH+x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_features(df):\n",
    "#     df['SQ25'] = df['F0_contour'].apply(get_SQ25)\n",
    "    df['SQ75'] = df['F0_contour'].apply(get_SQ75)\n",
    "#     df['F0_median'] = df['F0_contour'].apply(get_F0_median)\n",
    "#     df['sdmedian'] = df['F0_contour'].apply(get_sdmedian)\n",
    "    df['IDR'] = df['F0_contour'].apply(get_IDR)\n",
    "    df['voiced_segments'] = df['F0_contour'].apply(get_voiced_segments)\n",
    "    df['SVMeanRange'] = df['voiced_segments'].apply(get_voiced_segment_range)\n",
    "    df['SVMaxCurv'] = df['voiced_segments'].apply(get_max_voiced_curvature)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df = setup_df(REF_PATH)\n",
    "ref_df = get_audio_features(ref_df)\n",
    "temp_df = setup_df(TRAIN_PATH)\n",
    "# test_df = setup_df(TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the GMMs on the Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_GMMs = {}\n",
    "# features = [ 'SQ25', 'SQ75','F0_median', 'sdmedian', 'IDR', 'SVMeanRange','SVMaxCurv']\n",
    "features = [ 'SQ75','IDR', 'SVMeanRange','SVMaxCurv']\n",
    "\n",
    "for feature in features:\n",
    "    gmm = GaussianMixture(n_components=2)\n",
    "    gmm.fit(ref_df[feature].values.reshape(-1,1))\n",
    "    trained_GMMs[feature] = gmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IFN Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df['F0_contour_sum'] = ref_df['F0_contour'].apply(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df['F0_contour_length'] = ref_df['F0_contour'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df['F0_contour_mean'] = ref_df['F0_contour_sum']/ref_df['F0_contour_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_F0_ref = np.sum(ref_df['F0_contour_mean']) / 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample_df(df):\n",
    "    per_speaker_neutral_number = df[df['speech_type']==0]['speaker'].value_counts().values[0]\n",
    "    sampled_df = []\n",
    "    sampled_df.append(df[df['speech_type']==0])\n",
    "    speakers = df['speaker'].unique()\n",
    "    for speaker in speakers:\n",
    "        speaker_df = df[df['speaker'] == speaker]\n",
    "        speaker_emotional_df= speaker_df[speaker_df['speech_type']==1]\n",
    "        sampled_df.append(speaker_emotional_df.sample(n=per_speaker_neutral_number))\n",
    "    return pd.concat(sampled_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_GMM(df):\n",
    "    infered = np.zeros(shape=(1,len(features)))\n",
    "    for i in range(len(features)):\n",
    "        res = trained_GMMs[features[i]].score_samples([[df[features[i]]]])\n",
    "        infered[:,i] = res\n",
    "    return infered[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_changed_labels(neutral_list, emotional_list, row):\n",
    "    if row['file'] in neutral_list:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_S_s_F0(F0_ref, df):\n",
    "#     grouped_df_neu = df[df['speech_type']==0].groupby(['speaker']).sum().reset_index(level=0)\n",
    "#     grouped_df_neu = grouped_df_neu[['speaker','F0_contour_sum','F0_contour_length']]\n",
    "#     grouped_df_neu['F0_s_neu'] = grouped_df_neu['F0_contour_sum'] / grouped_df_neu['F0_contour_length']\n",
    "#     grouped_df_neu['S_s_F0'] = F0_ref / grouped_df_neu['F0_s_neu']\n",
    "\n",
    "    df_neu = df[df['speech_type']==0]\n",
    "    speakers = df['speaker'].unique()\n",
    "    grouped_df_neu = {}\n",
    "    for speaker in speakers:\n",
    "        speaker_df_neu = df_neu[df_neu['speaker']==speaker]\n",
    "        speaker_mean = speaker_df_neu['F0_contour_sum'].sum()/speaker_df_neu['F0_contour_length'].sum()\n",
    "        grouped_df_neu[speaker] = F0_ref/speaker_mean\n",
    "        \n",
    "        \n",
    "    \n",
    "#     return grouped_df_neu[['speaker','S_s_F0']].set_index('speaker').to_dict()['S_s_F0']\n",
    "    return grouped_df_neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalised_df(df, avg_F0_ref=avg_F0_ref, S0_func=get_S_s_F0):\n",
    "    df_norm = S0_func(avg_F0_ref, df)\n",
    "    df['F0_contour'] = df.apply(lambda x: x['F0_contour']/df_norm[x['speaker']], axis=1)\n",
    "    return df_norm, df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalised_df_infer(df, df_norm):\n",
    "    df['F0_contour'] = df.apply(lambda x: x['F0_contour']/df_norm[x['speaker']], axis=1)\n",
    "    return df_norm, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopping_criteria(df, count):\n",
    "    grouped_sampled_df = df.groupby('speaker')\n",
    "    neutral = []\n",
    "    emotional = []\n",
    "\n",
    "    for name, group in grouped_sampled_df:\n",
    "        neu_result = group[group['predicted_likelihood'] >= 0.7]\n",
    "        emo_result = group[group['predicted_likelihood'] < 0.7]\n",
    "\n",
    "        total = group.shape[0]\n",
    "        to_add = int(np.ceil(0.2 * total)) - neu_result.shape[0]\n",
    "        converted_neu_add = neu_result\n",
    "        if to_add > 0:\n",
    "            emo_result_sort = emo_result.sort_values('predicted_likelihood', ascending=False)\n",
    "            converted_neu_add = emo_result_sort.head(to_add)\n",
    "            emo_result.drop(converted_neu_add.index, inplace=True)\n",
    "\n",
    "        neutral.extend(converted_neu_add['file'].tolist())\n",
    "        emotional.extend(emo_result['file'].tolist()) \n",
    "\n",
    "    df['changed_speech_type'] = df.apply(lambda x: \\\n",
    "                                         get_changed_labels(neutral,emotional,x), axis=1) \n",
    "    \n",
    "    if count==0:\n",
    "        return df, 1000000\n",
    "\n",
    "    else:\n",
    "        changed_dict = (df['prev_changed_speech_type'] != df['changed_speech_type']).\\\n",
    "                        value_counts().to_dict()\n",
    "\n",
    "        if True not in changed_dict.keys():\n",
    "            changed_dict[True] = 0\n",
    "            epsilon = changed_dict[True]/changed_dict[False]\n",
    "        elif False not in changed_dict.keys():\n",
    "            epsilon = 1000000\n",
    "        else:\n",
    "            epsilon = changed_dict[True]/changed_dict[False]\n",
    "    \n",
    "    return df, epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "----------------------------------------\n",
      "Stage -  train\n",
      "None\n",
      "1    48\n",
      "0    48\n",
      "Name: speech_type, dtype: int64\n",
      "0\n",
      "1000000\n",
      "True\n",
      "----------------------------------------\n",
      "Stage -  test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.50      1.00      0.67        24\n",
      "\n",
      "    accuracy                           0.50        48\n",
      "   macro avg       0.25      0.50      0.33        48\n",
      "weighted avg       0.25      0.50      0.33        48\n",
      "\n",
      "=========================================\n",
      "----------------------------------------\n",
      "Stage -  train\n",
      "{15: 1.4674614092583878, 6: 0.6741689339891211, 8: 0.7943161392559523, 12: 0.7351361697381131, 2: 0.7674308481235315, 16: 0.8852915540059546, 3: 1.1081498631085704, 17: 1.4870837839925748, 1: 1.5720901716609383, 11: 1.432112160067652, 23: 1.0805133334181214, 5: 1.7364034626865223, 7: 1.2314673327525052, 21: 1.9243547640720389, 10: 0.7143033663787923, 19: 1.287622575542617, 14: 0.7202831186941038, 4: 0.7676826469333605, 22: 0.7921035618284483, 18: 0.820175216573084, 24: 0.7017131413026619, 20: 0.7104802818579349, 9: 1.9648755743897106, 13: 1.4864572253978834}\n",
      "1    48\n",
      "0    48\n",
      "Name: speech_type, dtype: int64\n",
      "1\n",
      "0.5483870967741935\n",
      "True\n",
      "----------------------------------------\n",
      "Stage -  test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.50      1.00      0.67        24\n",
      "\n",
      "    accuracy                           0.50        48\n",
      "   macro avg       0.25      0.50      0.33        48\n",
      "weighted avg       0.25      0.50      0.33        48\n",
      "\n",
      "=========================================\n",
      "----------------------------------------\n",
      "Stage -  train\n",
      "{15: 2.1534429876626127, 6: 0.45450375155602785, 8: 0.6309381290824815, 12: 0.5404251880572238, 2: 0.5889501066516029, 16: 0.7837411355942785, 3: 1.2279961191075437, 17: 2.2114181806136752, 1: 2.471467507832918, 11: 2.0509452390136356, 23: 1.1675090636943402, 5: 3.015096985229743, 7: 1.5165117916365691, 21: 3.703141258006752, 10: 0.5102292992200751, 19: 1.6579718970470023, 14: 0.5188077710757044, 4: 0.5893366464026107, 22: 0.6274280526613145, 18: 0.6726873858807053, 24: 0.49240133267684966, 20: 0.5047822309089303, 9: 3.8607360228332954, 13: 2.2095550829375736}\n",
      "1    48\n",
      "0    48\n",
      "Name: speech_type, dtype: int64\n",
      "2\n",
      "0.2\n",
      "True\n",
      "----------------------------------------\n",
      "Stage -  test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.50      1.00      0.67        24\n",
      "\n",
      "    accuracy                           0.50        48\n",
      "   macro avg       0.25      0.50      0.33        48\n",
      "weighted avg       0.25      0.50      0.33        48\n",
      "\n",
      "=========================================\n",
      "----------------------------------------\n",
      "Stage -  train\n",
      "{15: 4.637316701113281, 6: 0.20657366017850354, 8: 0.39808292273010204, 12: 0.2920593838866859, 2: 0.34686222812493434, 16: 0.6142501676226093, 3: 1.5079744685431886, 17: 4.890370369548698, 1: 6.108151642273856, 11: 4.2063763734326995, 23: 1.3630774138084347, 5: 9.090809830341488, 7: 2.2998080141727564, 21: 13.713255176751833, 10: 0.26033393778260916, 19: 2.748870811397636, 14: 0.26916150332854055, 4: 0.3473176827930758, 22: 0.39366596126636916, 18: 0.4525083191230167, 24: 0.24245907242193765, 20: 0.2548051006413966, 9: 14.905282638002657, 13: 4.88213366453527}\n",
      "1    48\n",
      "0    48\n",
      "Name: speech_type, dtype: int64\n",
      "3\n",
      "0.17073170731707318\n",
      "True\n",
      "----------------------------------------\n",
      "Stage -  test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.50      1.00      0.67        24\n",
      "\n",
      "    accuracy                           0.50        48\n",
      "   macro avg       0.25      0.50      0.33        48\n",
      "weighted avg       0.25      0.50      0.33        48\n",
      "\n",
      "=========================================\n",
      "----------------------------------------\n",
      "Stage -  train\n",
      "{15: 21.504706186424162, 6: 0.0426726770795439, 8: 0.1584700133693404, 12: 0.08529868371627052, 2: 0.12031340529979404, 16: 0.37730326842440365, 3: 2.2739869977781133, 17: 23.91572235135988, 1: 37.3095164850128, 11: 17.69360219497283, 23: 1.8579800360346905, 5: 82.64282337143342, 7: 5.289116902053236, 21: 188.05336754271093, 10: 0.0677737591613994, 19: 7.556290737753896, 14: 0.07244791487407996, 4: 0.12062957278075158, 22: 0.15497288905977447, 18: 0.20476377887553804, 24: 0.05878640179970638, 20: 0.06492563931287228, 9: 222.16745051874335, 13: 23.83522911838858}\n",
      "1    48\n",
      "0    48\n",
      "Name: speech_type, dtype: int64\n",
      "4\n",
      "0.09090909090909091\n",
      "True\n",
      "----------------------------------------\n",
      "Stage -  test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.50      1.00      0.67        24\n",
      "\n",
      "    accuracy                           0.50        48\n",
      "   macro avg       0.25      0.50      0.33        48\n",
      "weighted avg       0.25      0.50      0.33        48\n",
      "\n",
      "=========================================\n",
      "----------------------------------------\n",
      "Stage -  train\n",
      "{15: 462.4523881644295, 6: 0.0018209573691350294, 8: 0.02511274513727893, 12: 0.00727586544372835, 2: 0.014475315494832504, 16: 0.14235775636373751, 3: 5.1710168660639155, 17: 571.9617755873344, 1: 1392.000020345442, 11: 313.0635586339473, 23: 3.4520898143034713, 5: 6829.836254801944, 7: 27.974757603585218, 21: 35364.06904415393, 10: 0.0045932824308673684, 19: 57.09752971346529, 14: 0.005248700369601934, 4: 0.014551493829266645, 22: 0.02401659634353317, 18: 0.041928205139390246, 24: 0.0034558410365565224, 20: 0.004215338640185185, 9: 49358.37606999829, 13: 568.1181471260788}\n",
      "1    48\n",
      "0    48\n",
      "Name: speech_type, dtype: int64\n",
      "5\n",
      "0.5\n",
      "True\n",
      "----------------------------------------\n",
      "Stage -  test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.50      1.00      0.67        24\n",
      "\n",
      "    accuracy                           0.50        48\n",
      "   macro avg       0.25      0.50      0.33        48\n",
      "weighted avg       0.25      0.50      0.33        48\n",
      "\n",
      "=========================================\n",
      "----------------------------------------\n",
      "Stage -  train\n",
      "{15: 213862.21131898425, 6: 3.315885740207169e-06, 8: 0.0006306499683299266, 12: 5.2938217955240384e-05, 2: 0.00020953475867493794, 16: 0.020265730796917257, 3: 26.73941542911748, 17: 327140.2727330162, 1: 1937664.0566417107, 11: 98008.791744551, 23: 11.916924086017772, 5: 46646663.267407045, 7: 782.5870629793491, 21: 1250617379.359686, 10: 2.1098243489714838e-05, 19: 3260.127899380054, 14: 2.7548855569859498e-05, 4: 0.00021174597266318526, 22: 0.0005767968999282107, 18: 0.00175797438621079, 24: 1.1942837269948057e-05, 20: 1.7769079851438293e-05, 9: 2436249288.26738, 13: 322758.229093969}\n",
      "1    48\n",
      "0    48\n",
      "Name: speech_type, dtype: int64\n",
      "6\n",
      "0.24675324675324675\n",
      "True\n",
      "----------------------------------------\n",
      "Stage -  test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.50      1.00      0.67        24\n",
      "\n",
      "    accuracy                           0.50        48\n",
      "   macro avg       0.25      0.50      0.33        48\n",
      "weighted avg       0.25      0.50      0.33        48\n",
      "\n",
      "=========================================\n",
      "----------------------------------------\n",
      "Stage -  train\n",
      "{15: 45737045430.24586, 6: 1.0995098242109243e-11, 8: 3.977193825545375e-07, 12: 2.8024549202765335e-09, 2: 4.390481509296448e-08, 16: 0.00041069984473312074, 3: 714.9963374909255, 17: 107020758043.83224, 1: 3754541996401.2095, 11: 9605723259.226765, 23: 142.0130796719105, 5: 2175911193982860.5, 7: 612442.5111426438, 21: 1.5640438295564887e+18, 10: 4.451358783512946e-10, 19: 10628433.920316199, 14: 7.589394432089784e-10, 4: 4.483635693907841e-08, 22: 3.3269466376679433e-07, 18: 3.0904739425732037e-06, 24: 1.4263136205646035e-10, 20: 3.157401987667902e-10, 9: 5.935310594583313e+18, 13: 104172874447.87491}\n",
      "1    48\n",
      "0    48\n",
      "Name: speech_type, dtype: int64\n",
      "7\n",
      "0.06666666666666667\n",
      "True\n",
      "----------------------------------------\n",
      "Stage -  test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.50      1.00      0.67        24\n",
      "\n",
      "    accuracy                           0.50        48\n",
      "   macro avg       0.25      0.50      0.33        48\n",
      "weighted avg       0.25      0.50      0.33        48\n",
      "\n",
      "=========================================\n",
      "----------------------------------------\n",
      "Stage -  train\n",
      "{15: 2.0918773246883744e+21, 6: 1.2089218535363373e-22, 8: 1.5818070725956254e-13, 12: 7.853753580182158e-18, 2: 1.9276327883474027e-15, 16: 1.686743624638093e-07, 3: 511219.7626254376, 17: 1.1453442652276483e+22, 1: 1.409658560274038e+25, 11: 9.226991933285007e+19, 23: 20167.7147979004, 5: 4.7345895240999206e+30, 7: 375085829454.7073, 21: 2.4462331007737263e+36, 10: 1.9814595019557854e-19, 19: 112963607598528.03, 14: 5.75989078458354e-19, 4: 2.010298903568446e-15, 22: 1.106857392989003e-13, 18: 9.551029189723966e-12, 24: 2.0343705442081083e-20, 20: 9.969187311729214e-20, 9: 3.5227911854172933e+37, 13: 1.0851987770732716e+22}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    48\n",
      "0    48\n",
      "Name: speech_type, dtype: int64\n",
      "8\n",
      "0.06666666666666667\n",
      "True\n",
      "----------------------------------------\n",
      "Stage -  test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.50      1.00      0.67        24\n",
      "\n",
      "    accuracy                           0.50        48\n",
      "   macro avg       0.25      0.50      0.33        48\n",
      "weighted avg       0.25      0.50      0.33        48\n",
      "\n",
      "=========================================\n",
      "----------------------------------------\n",
      "Stage -  train\n",
      "{15: 4.3759507415453906e+42, 6: 1.4614920479577336e-44, 8: 2.5021136149135432e-26, 12: 6.168144529822405e-35, 2: 3.715768166711982e-30, 16: 2.845104055257255e-14, 3: 261345645698.8088, 17: 1.3118134858898616e+44, 1: 1.9871372565538745e+50, 11: 8.513738013690656e+39, 23: 406736720.16945076, 5: 2.2416337961716706e+61, 7: 1.4068937945772576e+23, 21: 5.984056383321039e+72, 10: 3.9261817578908674e-38, 19: 1.276077664167421e+28, 14: 3.3176341850330395e-37, 4: 4.041301681688493e-30, 22: 1.2251332884144121e-26, 18: 9.12221585829592e-23, 24: 4.138663511141593e-40, 20: 9.938469565634279e-39, 9: 1.241005773605378e+75, 13: 1.1776563857613238e+44}\n",
      "1    48\n",
      "0    48\n",
      "Name: speech_type, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-747-6e43cc9d519e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speech_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mldc_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inferred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speech_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_likelihood'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mldc_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inferred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Brihi/IIIT/iterative-feature-normalisation-ICASSP-2011/venv/ifn/lib/python3.7/site-packages/sklearn/discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_svd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lsqr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_lsqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinkage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eigen'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_eigen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinkage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Brihi/IIIT/iterative-feature-normalisation-ICASSP-2011/venv/ifn/lib/python3.7/site-packages/sklearn/discriminant_analysis.py\u001b[0m in \u001b[0;36m_solve_lsqr\u001b[0;34m(self, X, y, shrinkage)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_class_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_class_cov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovariance_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         self.intercept_ = (-0.5 * np.diag(np.dot(self.means_, self.coef_.T)) +\n\u001b[1;32m    296\u001b[0m                            np.log(self.priors_))\n",
      "\u001b[0;32m/Volumes/Brihi/IIIT/iterative-feature-normalisation-ICASSP-2011/venv/ifn/lib/python3.7/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \"\"\"\n\u001b[0;32m-> 1157\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_validated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m     \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_validated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Brihi/IIIT/iterative-feature-normalisation-ICASSP-2011/venv/ifn/lib/python3.7/site-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m_asarray_validated\u001b[0;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'masked arrays are not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mtoarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_chkfinite\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobjects_ok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Brihi/IIIT/iterative-feature-normalisation-ICASSP-2011/venv/ifn/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AllFloat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         raise ValueError(\n\u001b[0;32m--> 499\u001b[0;31m             \"array must not contain infs or NaNs\")\n\u001b[0m\u001b[1;32m    500\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "# for every epoch\n",
    "epoch = 0\n",
    "\n",
    "for iterations in range(1):\n",
    "\n",
    "    sampled_df = stratified_sample_df(temp_df)\n",
    "    \n",
    "    train_df, test_df = train_test_split(sampled_df, test_size = 0.33, stratify = sampled_df[['speaker','speech_type']])\n",
    "    \n",
    "    train_df = get_audio_features(train_df)\n",
    "    \n",
    "\n",
    "    test_df['F0_contour_sum'] = test_df['F0_contour'].apply(sum)\n",
    "    test_df['F0_contour_length'] = test_df['F0_contour'].apply(len)\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    # for 400 iterations\n",
    "    sampled_df_norm = None\n",
    "    ldc_clf = None\n",
    "    epsilon = 1000000\n",
    "    max_iters = 1000\n",
    "    \n",
    "    ldc_clf = LinearDiscriminantAnalysis(solver='lsqr')\n",
    "\n",
    "    \n",
    "    while epsilon > 0.05 and count < max_iters:\n",
    "        \n",
    "        print('=========================================')   \n",
    "\n",
    "            \n",
    "        for stage in ['train', 'test']:\n",
    "            \n",
    "            print('----------------------------------------')   \n",
    "            print('Stage - ', stage)\n",
    "\n",
    "\n",
    "        \n",
    "            if stage == 'train':\n",
    "                \n",
    "                train_df['F0_contour_sum'] = train_df['F0_contour'].apply(sum)\n",
    "                train_df['F0_contour_length'] = train_df['F0_contour'].apply(len)\n",
    "\n",
    "\n",
    "                if count != 0:\n",
    "                    train_df['prev_changed_speech_type'] = train_df['changed_speech_type']\n",
    "                    sampled_df_norm, train_df = get_normalised_df(train_df, avg_F0_ref=avg_F0_ref, S0_func=get_S_s_F0)\n",
    "\n",
    "                print(sampled_df_norm)\n",
    "\n",
    "                train_df = get_audio_features(train_df)\n",
    "                train_df['inferred'] = train_df.apply(infer_GMM,axis=1)\n",
    "\n",
    "                print(train_df['speech_type'].value_counts())\n",
    "                ldc_clf.fit(np.array(train_df['inferred'].tolist()),train_df['speech_type'].values)\n",
    "\n",
    "                train_df['predicted_likelihood'] = ldc_clf.predict_proba(np.array(train_df['inferred'].tolist()))[:,0]\n",
    "\n",
    "                train_df, epsilon = get_stopping_criteria(train_df, count)\n",
    "\n",
    "                print(count)\n",
    "                print(epsilon)\n",
    "\n",
    "                print(epsilon > 0.05)\n",
    "\n",
    "            else:\n",
    "                sampled_df_test = test_df\n",
    "                if count!=0:\n",
    "                    _, sampled_df_test = get_normalised_df_infer(test_df, sampled_df_norm)\n",
    "                sampled_df_test = get_audio_features(sampled_df_test)\n",
    "                sampled_df_test['inferred'] = sampled_df_test.apply(infer_GMM,axis=1)\n",
    "\n",
    "                sampled_df_test['predicted_likelihood'] = ldc_clf.predict_proba(np.array(sampled_df_test['inferred'].tolist()))[:,0]\n",
    "                sampled_df_test['predicted_speech_type'] = sampled_df_test['predicted_likelihood'].\\\n",
    "                                                            apply(lambda x: 0 if x >=0.7 else 1)\n",
    "\n",
    "                print(classification_report(sampled_df_test['speech_type'],sampled_df_test['predicted_speech_type']))\n",
    "                \n",
    "        count+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348.5416666666667"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_df['F0_contour_length'].sum()/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ifn",
   "language": "python",
   "name": "ifn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
