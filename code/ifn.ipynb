{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import os\n",
    "from feature_extraction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"../data/processed/train/\"\n",
    "TEST_PATH = \"../data/processed/test/\"\n",
    "REF_PATH = \"../data/processed/reference/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_df(PATH):\n",
    "    all_files = os.listdir(PATH)\n",
    "    df = pd.DataFrame(all_files, columns=['file'])\n",
    "    df['speaker'] = df['file'].apply(lambda x: int(x.split('.')[0].split('-')[-1]))\n",
    "    # 0 for neutral, 1 for emotional\n",
    "    df['speech_type'] = df['file'].apply(lambda x: 0 if int(x.split('.')[0].split('-')[2])==1 else 1)\n",
    "    df['F0_contour'] = df['file'].apply(lambda x: get_F0_contour(PATH+x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_features(df):\n",
    "    df['SQ25'] = df['F0_contour'].apply(get_SQ25)\n",
    "    df['SQ75'] = df['F0_contour'].apply(get_SQ75)\n",
    "    df['F0_median'] = df['F0_contour'].apply(get_F0_median)\n",
    "    df['sdmedian'] = df['F0_contour'].apply(get_sdmedian)\n",
    "    df['IDR'] = df['F0_contour'].apply(get_IDR)\n",
    "    df['voiced_segments'] = df['F0_contour'].apply(get_voiced_segments)\n",
    "    df['SVMeanRange'] = df['voiced_segments'].apply(get_voiced_segment_range)\n",
    "    df['SVMaxCurv'] = df['voiced_segments'].apply(get_max_voiced_curvature)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df = setup_df(REF_PATH)\n",
    "ref_df = get_audio_features(ref_df)\n",
    "train_df = setup_df(TRAIN_PATH)\n",
    "test_df = setup_df(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_audio_features(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the GMMs on the Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Brihi/IIIT/iterative-feature-normalisation-ICASSP-2011/venv/ifn/lib/python3.7/site-packages/sklearn/mixture/_base.py:147: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  random_state=random_state).fit(X).labels_\n",
      "/Volumes/Brihi/IIIT/iterative-feature-normalisation-ICASSP-2011/venv/ifn/lib/python3.7/site-packages/sklearn/mixture/_base.py:147: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  random_state=random_state).fit(X).labels_\n",
      "/Volumes/Brihi/IIIT/iterative-feature-normalisation-ICASSP-2011/venv/ifn/lib/python3.7/site-packages/sklearn/mixture/_base.py:147: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  random_state=random_state).fit(X).labels_\n"
     ]
    }
   ],
   "source": [
    "trained_GMMs = {}\n",
    "features = [ 'SQ25', 'SQ75','F0_median', 'sdmedian', 'IDR', 'SVMeanRange','SVMaxCurv']\n",
    "for feature in features:\n",
    "    gmm = GaussianMixture(n_components=2)\n",
    "    gmm.fit(ref_df[feature].values.reshape(-1,1))\n",
    "    trained_GMMs[feature] = gmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IFN Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df['F0_contour_sum'] = ref_df['F0_contour'].apply(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df['F0_contour_length'] = ref_df['F0_contour'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_F0_ref = np.sum(ref_df['F0_contour_sum']) / np.sum(ref_df['F0_contour_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['F0_contour_sum'] = train_df['F0_contour'].apply(sum)\n",
    "train_df['F0_contour_length'] = train_df['F0_contour'].apply(len)\n",
    "test_df['F0_contour_sum'] = test_df['F0_contour'].apply(sum)\n",
    "test_df['F0_contour_length'] = test_df['F0_contour'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_S_s_F0(F0_ref, df):\n",
    "    grouped_df_neu = df[df['speech_type']==0].groupby(['speaker']).sum().reset_index(level=0)\n",
    "    grouped_df_neu = grouped_df_neu[['speaker','F0_contour_sum','F0_contour_length']]\n",
    "    grouped_df_neu['F0_s_neu'] = grouped_df_neu['F0_contour_sum'] / grouped_df_neu['F0_contour_length']\n",
    "    grouped_df_neu['S_s_F0'] = F0_ref / grouped_df_neu['F0_s_neu']\n",
    "    \n",
    "    return grouped_df_neu[['speaker','S_s_F0']].set_index('speaker').to_dict()['S_s_F0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample_df(df):\n",
    "    per_speaker_neutral_number = df[df['speech_type']==0]['speaker'].value_counts().values[0]\n",
    "    sampled_df = []\n",
    "    sampled_df.append(df[df['speech_type']==0])\n",
    "    speakers = df['speaker'].unique()\n",
    "    for speaker in speakers:\n",
    "        speaker_df = df[df['speaker'] == speaker]\n",
    "        speaker_emotional_df= speaker_df[speaker_df['speech_type']==1]\n",
    "        sampled_df.append(speaker_emotional_df.sample(n=per_speaker_neutral_number))\n",
    "    return pd.concat(sampled_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_GMM(df):\n",
    "    infered = np.zeros(shape=(1,len(features)))\n",
    "    for i in range(len(features)):\n",
    "        res = trained_GMMs[features[i]].score_samples([[df[features[i]]]])\n",
    "        infered[:,i] = res\n",
    "    return infered[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_changed_labels(neutral_list, emotional_list, row):\n",
    "    if row['file'] in neutral_list:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every epoch\n",
    "\n",
    "# for 400 iterations\n",
    "\n",
    "# subsample the df to represent equal number of emotional and neutral classes\n",
    "sampled_df = stratified_sample_df(train_df)\n",
    "sampled_df_norm = get_S_s_F0(avg_F0_ref, sampled_df)\n",
    "sampled_df['F0_contour'] = sampled_df.apply(lambda x: x['F0_contour']/sampled_df_norm[x['speaker']], axis=1)\n",
    "sampled_df = get_audio_features(sampled_df)\n",
    "sampled_df['inferred'] = sampled_df.apply(infer_GMM,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "                           solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(np.array(sampled_df['inferred'].tolist()),sampled_df['speech_type'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sampled_df['predicted_likelihood'] = clf.predict_proba(np.array(sampled_df['inferred'].tolist()))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_sampled_df = sampled_df.groupby('speaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral = []\n",
    "emotional = []\n",
    "\n",
    "for name, group in grouped_sampled_df:\n",
    "    neu_result = group[group['predicted_likelihood'] >= 0.7]\n",
    "    emo_result = group[group['predicted_likelihood'] < 0.7]\n",
    "        \n",
    "    total = group.shape[0]\n",
    "    to_add = int(0.2 * total) - neu_result.shape[0]\n",
    "    converted_neu_add = None\n",
    "    if to_add > 0:\n",
    "        emo_result_sort = emo_result.sort_values('predicted_likelihood', ascending=False)\n",
    "        converted_neu_add = emo_result_sort.head(to_add)\n",
    "        emo_result.drop(converted_neu_add.index, inplace=True)\n",
    "    \n",
    "    neutral.extend(converted_neu_add['file'].tolist())\n",
    "    emotional.extend(emo_result['file'].tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['changed_speech_type'] = sampled_df.app "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ifn",
   "language": "python",
   "name": "ifn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
